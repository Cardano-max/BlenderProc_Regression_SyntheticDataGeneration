"""
COCO to YOLO Annotation Converter
==================================
Converts COCO format annotations to YOLO format for training.

Author: Maidah Binte Tariq
Date: January 2025
"""

import os
import json
import argparse
from pathlib import Path
from typing import Dict, List, Tuple
from tqdm import tqdm


def coco_to_yolo_bbox(bbox: List[float], img_width: int, img_height: int) -> Tuple[float, float, float, float]:
    """
    Convert COCO bbox [x, y, width, height] to YOLO format [x_center, y_center, width, height] (normalized).
    
    Args:
        bbox: COCO format bbox [x_min, y_min, width, height]
        img_width: Image width
        img_height: Image height
    
    Returns:
        YOLO format bbox (x_center, y_center, width, height) normalized to [0, 1]
    """
    x, y, w, h = bbox
    
    # Calculate center
    x_center = x + w / 2
    y_center = y + h / 2
    
    # Normalize
    x_center /= img_width
    y_center /= img_height
    w /= img_width
    h /= img_height
    
    return x_center, y_center, w, h


def convert_coco_to_yolo(coco_json_path: str, output_dir: str, images_dir: str = None) -> None:
    """
    Convert COCO annotations to YOLO format.
    
    Args:
        coco_json_path: Path to COCO JSON file
        output_dir: Output directory for YOLO labels
        images_dir: Optional images directory (for creating data.yaml)
    """
    # Load COCO annotations
    with open(coco_json_path, 'r') as f:
        coco_data = json.load(f)
    
    # Create output directory
    os.makedirs(output_dir, exist_ok=True)
    
    # Build image ID to info mapping
    images = {img['id']: img for img in coco_data['images']}
    
    # Build category mapping
    categories = {cat['id']: cat['name'] for cat in coco_data['categories']}
    
    # Group annotations by image
    annotations_by_image: Dict[int, List] = {}
    for ann in coco_data['annotations']:
        img_id = ann['image_id']
        if img_id not in annotations_by_image:
            annotations_by_image[img_id] = []
        annotations_by_image[img_id].append(ann)
    
    print(f"Converting {len(images)} images...")
    print(f"Categories: {categories}")
    
    # Convert each image's annotations
    for img_id, img_info in tqdm(images.items(), desc="Converting"):
        # Get image dimensions
        img_width = img_info['width']
        img_height = img_info['height']
        
        # Get filename without extension
        filename = Path(img_info['file_name']).stem
        
        # Create YOLO label file
        label_path = os.path.join(output_dir, f"{filename}.txt")
        
        # Get annotations for this image
        img_annotations = annotations_by_image.get(img_id, [])
        
        # Write YOLO format labels
        with open(label_path, 'w') as f:
            for ann in img_annotations:
                # Get category (YOLO uses 0-indexed classes)
                category_id = ann['category_id'] - 1  # Convert to 0-indexed
                
                # Convert bbox
                bbox = ann['bbox']
                x_center, y_center, width, height = coco_to_yolo_bbox(
                    bbox, img_width, img_height
                )
                
                # Write line: class_id x_center y_center width height
                f.write(f"{category_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\n")
    
    # Create data.yaml for YOLO training
    data_yaml_path = os.path.join(output_dir, '..', 'data.yaml')
    
    # Prepare class names
    class_names = [categories[i] for i in sorted(categories.keys())]
    
    data_yaml = {
        'path': os.path.dirname(os.path.abspath(output_dir)),
        'train': 'images/train',
        'val': 'images/val',
        'test': 'images/test',
        'nc': len(class_names),
        'names': class_names,
    }
    
    # Write data.yaml
    with open(data_yaml_path, 'w') as f:
        f.write(f"# Synthetic Shackle Wear Detection Dataset\n")
        f.write(f"# Auto-generated by convert_to_yolo.py\n\n")
        f.write(f"path: {data_yaml['path']}\n")
        f.write(f"train: images/train\n")
        f.write(f"val: images/val\n")
        f.write(f"test: images/test\n\n")
        f.write(f"# Number of classes\n")
        f.write(f"nc: {data_yaml['nc']}\n\n")
        f.write(f"# Class names\n")
        f.write(f"names:\n")
        for name in class_names:
            f.write(f"  - {name}\n")
    
    print(f"\nConversion complete!")
    print(f"YOLO labels saved to: {output_dir}")
    print(f"data.yaml saved to: {data_yaml_path}")
    print(f"\nClass mapping:")
    for i, name in enumerate(class_names):
        print(f"  {i}: {name}")


def split_dataset(images_dir: str, labels_dir: str, output_dir: str,
                  train_ratio: float = 0.7, val_ratio: float = 0.2) -> None:
    """
    Split dataset into train/val/test sets.
    
    Args:
        images_dir: Directory containing images
        labels_dir: Directory containing YOLO labels
        output_dir: Output directory for split dataset
        train_ratio: Proportion for training
        val_ratio: Proportion for validation
    """
    import random
    import shutil
    
    # Get all images
    image_files = list(Path(images_dir).glob('*.png')) + list(Path(images_dir).glob('*.jpg'))
    random.shuffle(image_files)
    
    # Calculate split sizes
    total = len(image_files)
    train_size = int(total * train_ratio)
    val_size = int(total * val_ratio)
    
    splits = {
        'train': image_files[:train_size],
        'val': image_files[train_size:train_size + val_size],
        'test': image_files[train_size + val_size:],
    }
    
    print(f"Splitting {total} images:")
    print(f"  Train: {len(splits['train'])}")
    print(f"  Val: {len(splits['val'])}")
    print(f"  Test: {len(splits['test'])}")
    
    # Create directories and copy files
    for split_name, files in splits.items():
        img_dir = os.path.join(output_dir, 'images', split_name)
        lbl_dir = os.path.join(output_dir, 'labels', split_name)
        os.makedirs(img_dir, exist_ok=True)
        os.makedirs(lbl_dir, exist_ok=True)
        
        for img_file in tqdm(files, desc=f"Copying {split_name}"):
            # Copy image
            shutil.copy(img_file, img_dir)
            
            # Copy corresponding label
            label_file = Path(labels_dir) / f"{img_file.stem}.txt"
            if label_file.exists():
                shutil.copy(label_file, lbl_dir)
    
    print(f"\nDataset split saved to: {output_dir}")


def main():
    parser = argparse.ArgumentParser(description="Convert COCO annotations to YOLO format")
    
    parser.add_argument(
        "--input", "-i",
        type=str,
        default="./output/annotations/coco_annotations.json",
        help="Input COCO JSON file"
    )
    
    parser.add_argument(
        "--output", "-o",
        type=str,
        default="./output/yolo_labels",
        help="Output directory for YOLO labels"
    )
    
    parser.add_argument(
        "--split",
        action="store_true",
        help="Also split into train/val/test sets"
    )
    
    parser.add_argument(
        "--images-dir",
        type=str,
        default="./output/images",
        help="Images directory (for splitting)"
    )
    
    parser.add_argument(
        "--train-ratio",
        type=float,
        default=0.7,
        help="Training set ratio (default: 0.7)"
    )
    
    parser.add_argument(
        "--val-ratio",
        type=float,
        default=0.2,
        help="Validation set ratio (default: 0.2)"
    )
    
    args = parser.parse_args()
    
    # Convert COCO to YOLO
    convert_coco_to_yolo(args.input, args.output)
    
    # Optionally split dataset
    if args.split:
        split_output = os.path.join(os.path.dirname(args.output), 'dataset')
        split_dataset(
            args.images_dir, 
            args.output, 
            split_output,
            args.train_ratio,
            args.val_ratio
        )


if __name__ == "__main__":
    main()
